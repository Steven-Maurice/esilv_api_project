# -*- coding: utf-8 -*-
"""api.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1c9Jy3X1FWeok2kbGnFyG2T8-lIVQz7jJ
""" 
import requests
from bs4 import BeautifulSoup

def get_data(url):
    response = requests.get(url)
    if response.status_code == 200:
        soup = BeautifulSoup(response.content, "html.parser")
        articles = []
        article_tags = soup.find_all("article", class_="post")
        for article_tag in article_tags[:10]:  # Limite à 10 articles pour cet exemple
            title_tag = article_tag.find("a", rel="bookmark")
            date_tag = article_tag.find("span", class_="post-date")
            if title_tag:
                title = title_tag.text.strip()
                date = date_tag.text.strip() if date_tag else "Date not available"
                url = title_tag.get('href')  # Récupère l'URL de l'article
                articles.append({"title": title, "date": date, "url": url})
            else:
                print("Failed to extract title from an article.")
        return articles
    else:
        print("Failed to retrieve data from the website.")
        return []

url = "https://www.artificialintelligence-news.com/"
articles = get_data(url)
for article in articles:
    print("Title:", article["title"])
    print("URL:", article["url"])  # Affiche l'URL de chaque article
    print("Date:", article["date"])
    print("--------------------")
