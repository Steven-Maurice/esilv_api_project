{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTATION DES MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #pip install requests\n",
    "from xml.etree import ElementTree #pip install xml.etree # Pour lire les données extraites par l'api arXiv\n",
    "import datetime as dt #pip install datetime #Pour convertir les dates de publicaiton de str en datetime pour les ranger par ordre chronologique\n",
    "\n",
    "# 3 modules pour l'extraction du texte du pdf, manque tjrs les images...\n",
    "import io\n",
    "import pdfminer #pip install pdfminer\n",
    "from pdfminer.high_level import extract_text  #pip install pdfminer.six"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de l'API, présentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, Response\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'Présentation de notre API'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appel à l'API et stockage des données dans une liste pour éviter de faire plein de fois le même appel pour la même requête."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callAPI(urlreq, param):\n",
    "    arxiv_url = urlreq\n",
    "    research_type = param\n",
    "    rep = requests.get(arxiv_url, params=research_type)\n",
    "    root = ElementTree.fromstring(rep.content)\n",
    "    return root\n",
    "\n",
    "def articlesAPI():\n",
    "    articles = []\n",
    "    # Ici on défini notre url de requête et nos paramètres pour faire appel à l'api\n",
    "    # On va chercher partout où le titre contient AI, et on garde 5 artciles comme dit la consigne\n",
    "    root = callAPI(\"http://export.arxiv.org/api/query?\",{\"search_query\": \"all:ai\", \"max_results\" : 5})\n",
    "    # On regarde élément par élément dans notre recherche : le titre/l'abstract/le nom de l'auteur/\n",
    "    #la date de publication/le lien pour accéder à l\"article/l'identifiant associé\n",
    "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        abs = entry.find('{http://www.w3.org/2005/Atom}summary').text\n",
    "        auteur = entry.find('{http://www.w3.org/2005/Atom}author').find('{http://www.w3.org/2005/Atom}name').text\n",
    "        published = entry.find('{http://www.w3.org/2005/Atom}published').text[0:10]\n",
    "        link = entry.find('{http://www.w3.org/2005/Atom}id').text\n",
    "        id = link[21:]\n",
    "        urlpdf = f\"http://arxiv.org/pdf/{id}\"\n",
    "\n",
    "\n",
    "        articles.append([id, link, auteur, title, published, urlpdf, abs])\n",
    "\n",
    "    for article in articles: # pour trier les artciles dans l'ordre chronologik ; pas trouvé comment faire avec l'api directement\n",
    "        article[4] = dt.datetime.strptime(article[4], '%Y-%m-%d')\n",
    "    articles.sort(key=lambda x: x[4], reverse = True)\n",
    "    return articles\n",
    "\n",
    "larticles = articlesAPI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ère route : get_data\n",
    "\n",
    "récupère 5 liens d'articles et les range par ordre chronologique de sortie, puis les affiche\n",
    "\n",
    "AMODIF, un peu nul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://arxiv.org/abs/2402.07632v1', 'http://arxiv.org/abs/2403.05551v1', 'http://arxiv.org/abs/2305.15922v1', 'http://arxiv.org/abs/2211.05075v1', 'http://arxiv.org/abs/2103.15294v1']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response 181 bytes [200 OK]>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@app.route('/get_data')\n",
    "def get_data():\n",
    "    liste = larticles\n",
    "    a = [i[1] for i in liste]\n",
    "    html = \"<br>\".join(a)\n",
    "    return Response(html, mimetype='text/html')\n",
    "\n",
    "get_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2ème route : Affiche les informations relatives aux 5 articles précédents, id, lien, auteur, titre, date de publi, lien pdf, abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response 5849 bytes [200 OK]>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@app.route('/articles')\n",
    "def articles():\n",
    "    art = larticles \n",
    "    commentaire = \"Pour voir le contenu d'un article en particulier : modifier le chemin, /articles devient article/ID où ID est l'identifiant de l'article choisi\"\n",
    "    html = commentaire +  \"<br>\"+ \"<br>\".join([f\"ID: {a[0]}<br>Link: {a[1]}<br>Authors: {a[2]}<br>Title: {a[3]}<br>Published: {a[4]}<br>PDF: {a[5]}<br>Summary: {a[6]}<br><br>\" for a in art])\n",
    "    return Response(html, mimetype='text/html')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3ème route : Affiche le lien pdf et son contenu d'un article identifié par son id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/article/<id>')\n",
    "def article_content(id):\n",
    "    urlpdf = f\"http://arxiv.org/pdf/{id}\"\n",
    "    response = requests.get(urlpdf)\n",
    "\n",
    "    text = extract_text(io.BytesIO(response.content))\n",
    "\n",
    "    # Convertir les sauts de ligne en balises <br> pour l'affichage HTML\n",
    "    html_content = \"Lien pour accéder au pdf direct : \" + urlpdf +'<br>'+'<br>'+'<br>' + text.replace('\\n', '<br>')\n",
    "\n",
    "    return Response(html_content, mimetype='text/html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.route('/ml') # reste à compléter\n",
    "def ml_method():\n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Apr/2024 18:52:46] \"GET /articles HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# faire tourner le serveur\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
