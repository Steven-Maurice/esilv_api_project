{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #pip install requests\n",
    "from xml.etree import ElementTree #pip install xml.etree\n",
    "import datetime as dt #pip install datetime\n",
    "\n",
    "import io\n",
    "import pdfminer #pip install pdfminer\n",
    "from pdfminer.high_level import extract_text  #pip install pdfminer.six\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Apr/2024 13:52:23] \"GET /article/2402.07632v1 HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, Response\n",
    "\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return 'AI ARTCILES'\n",
    "\n",
    "\n",
    "@app.route('/get_data')\n",
    "def get_data():\n",
    "    articles = []\n",
    "    arxiv_url = \"http://export.arxiv.org/api/query?\"\n",
    "    research_type = {\"search_query\": \"all:ai\", \"max_results\" : 5}\n",
    "\n",
    "    rep = requests.get(arxiv_url, params=research_type)\n",
    "    root = ElementTree.fromstring(rep.content)\n",
    "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "        published = entry.find('{http://www.w3.org/2005/Atom}published').text[0:10] \n",
    "\n",
    "        articles.append([entry.find('{http://www.w3.org/2005/Atom}id').text, published])\n",
    "\n",
    "    for article in articles: # pour trier les artciles dans l'ordre chronologik\n",
    "        article[1] = dt.datetime.strptime(article[1], '%Y-%m-%d')\n",
    "    articles.sort(key=lambda x: x[1], reverse = True)\n",
    "    articles = [article[0] for article in articles] #On les a rangé par odre chrono mais pour cette route on n'a pas besoin des dates de publi\n",
    "    \n",
    "    html = \"<br>\".join(articles)\n",
    "    return Response(html, mimetype='text/html')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "@app.route('/articles')\n",
    "def articles():\n",
    "    articles = []\n",
    "    arxiv_url = \"http://export.arxiv.org/api/query?\"\n",
    "    research_type = {\"search_query\": \"all:ai\", \"max_results\" : 5}\n",
    "\n",
    "    rep = requests.get(arxiv_url, params=research_type)\n",
    "    root = ElementTree.fromstring(rep.content)\n",
    "    for entry in root.findall('{http://www.w3.org/2005/Atom}entry'):\n",
    "        title = entry.find('{http://www.w3.org/2005/Atom}title').text\n",
    "        abs = entry.find('{http://www.w3.org/2005/Atom}summary').text\n",
    "        auteur = entry.find('{http://www.w3.org/2005/Atom}author').find('{http://www.w3.org/2005/Atom}name').text\n",
    "        published = entry.find('{http://www.w3.org/2005/Atom}published').text[0:10] \n",
    "        link = entry.find('{http://www.w3.org/2005/Atom}id').text\n",
    "        id = link[21:]\n",
    "        urlpdf = f\"http://arxiv.org/pdf/{id}\"\n",
    "\n",
    "        articles.append([id, link, auteur, title, published, urlpdf, abs])\n",
    "    \n",
    "    \n",
    "    for article in articles: # pour trier les artciles dans l'ordre chronologik\n",
    "        article[4] = dt.datetime.strptime(article[4], '%Y-%m-%d')\n",
    "    articles.sort(key=lambda x: x[4], reverse = True)\n",
    "\n",
    "    html = \"<br>\".join([f\"ID: {a[0]}<br>Link: {a[1]}<br>Authors: {a[2]}<br>Title: {a[3]}<br>Published: {a[4]}<br>PDF: {a[5]}<br>Summary: {a[6]}<br><br>\" for a in articles])\n",
    "    return Response(html, mimetype='text/html')\n",
    "\n",
    "\n",
    "@app.route('/article/<id>')\n",
    "def article_content(id):\n",
    "    urlpdf = f\"http://arxiv.org/pdf/{id}\"\n",
    "    response = requests.get(urlpdf)\n",
    "\n",
    "    text = extract_text(io.BytesIO(response.content))\n",
    "\n",
    "    # Convertir les sauts de ligne en balises <br> pour l'affichage HTML\n",
    "    html_content = \"Lien pour accéder au pdf direct : \" + urlpdf +'<br>'+'<br>'+'<br>' + text.replace('\\n', '<br>')\n",
    "\n",
    "    return Response(html_content, mimetype='text/html')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@app.route('/ml')\n",
    "def ml_method():\n",
    "    return \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
